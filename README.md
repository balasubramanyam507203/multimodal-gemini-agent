# Multimodal-Gemini-Agent ğŸš€

A local, multimodal AI agent built using Google Gemini + MongoDB for retrieval, enabling PDF & image question-answering using a RAG (retrieval-augmented generation) pipeline.

---

## âœ¨ Features

- **ğŸ“„ PDF Ingestion**  
  Automatically reads PDFs, splits them into text chunks, embeds them, and stores them in MongoDB.

- **ğŸ§  Multimodal AI Reasoning**  
  Supports text + image queries. Ask questions about documents, charts, diagrams, screenshots, etc.

- **ğŸ” Retrieval-Augmented Generation (RAG)**  
  Uses embedding-based search to fetch relevant chunks before sending context to Gemini for accurate answers.

- **ğŸ”’ Secure Configuration**  
  API keys and database credentials stay in `.env` (not committed to GitHub).

---

## ğŸ“ Project Structure
'''multimodal-gemini-agent/
â”œâ”€â”€ config.py # Loads API keys + MongoDB connection
â”œâ”€â”€ ingest.py # PDF ingestion + embedding
â”œâ”€â”€ agents.py # Retrieval + multimodal agent logic
â”œâ”€â”€ main.py # CLI interface for asking questions
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ docs/ # Place your PDF files here
â”‚ â””â”€â”€ images/ # Optional: charts/images for analysis
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md'''


